import streamlit as st
from openai import OpenAI
import pandas as pd
import datetime
import time

# --- ãƒšãƒ¼ã‚¸è¨­å®š ---
st.set_page_config(page_title="AI FGI Simulator", layout="wide")

st.title("ğŸ‘¥ AI Focus Group Interview Simulator")
st.markdown("""
è¨­å®šã—ãŸãƒšãƒ«ã‚½ãƒŠã¨AIãƒ¢ãƒ‡ãƒ¬ãƒ¼ã‚¿ãƒ¼ã«ã‚ˆã‚‹FGIã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚¢ãƒ—ãƒªã§ã™ã€‚
è¨­å®šã—ãŸã€Œæ‰€è¦æ™‚é–“ã€ã«åˆã‚ã›ã¦ã€AIãŒè­°è«–ã®ãƒšãƒ¼ã‚¹é…åˆ†ï¼ˆå°å…¥â†’æ·±æ˜ã‚Šâ†’ã¾ã¨ã‚ï¼‰ã‚’ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ã—ã¾ã™ã€‚
""")

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š ---
with st.sidebar:
    st.header("ğŸ”§ è¨­å®š")
    
    # APIã‚­ãƒ¼è¨­å®šï¼ˆSecretså„ªå…ˆã€ãªã‘ã‚Œã°æ‰‹å…¥åŠ›ï¼‰
    if "OPENAI_API_KEY" in st.secrets:
        api_key = st.secrets["OPENAI_API_KEY"]
    else:
        api_key = st.text_input("OpenAI API Key", type="password")

    if not api_key:
        st.warning("APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        st.stop()
    
    client = OpenAI(api_key=api_key)

    # ãƒ†ãƒ¼ãƒè¨­å®š
    topic = st.text_input("ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼ã®ãƒ†ãƒ¼ãƒ", value="æ–°ã—ã„ã‚³ãƒ¼ãƒ’ãƒ¼ãƒ–ãƒ©ãƒ³ãƒ‰ã®ã‚³ãƒ³ã‚»ãƒ—ãƒˆå—å®¹æ€§")
    
    # æ™‚é–“è¨­å®šï¼ˆNew!ï¼‰
    target_duration = st.slider("æƒ³å®šã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼æ™‚é–“ï¼ˆåˆ†ï¼‰", 30, 120, 60, step=10)
    
    # ãƒ¢ãƒ‡ãƒ¬ãƒ¼ã‚¿ãƒ¼ã®è¨­å®š
    moderator_style = st.slider("ãƒ¢ãƒ‡ãƒ¬ãƒ¼ã‚¿ãƒ¼ã®æ·±æ˜ã‚Šåº¦", 1, 5, 2, help="1:é›‘è«‡é‡è¦– â†” 5:åˆ†æé‡è¦–")
    
    # å‚åŠ è€…è¨­å®š
    default_participants = """
ç”°ä¸­ã•ã‚“: 40æ­³ã€æ—¢å©šã€å­ä¾›1äººï¼ˆ7æ­³å°å­¦ä¸€å¹´ç”Ÿå¥³å­ï¼‰ã€‚ã‚­ãƒ£ãƒªã‚¢ã‚¦ãƒ¼ãƒãƒ³ã§å¹´å800ä¸‡ã€‚å¿™ã—ã„ãŒé€±æœ«ã¯å®¶æ—ã¨ã®æ™‚é–“ã‚’å¤§åˆ‡ã«ã—ãŸã„ã€‚å°‘ã—ç–²ã‚Œæ°—å‘³ã€‚
ä½è—¤ã•ã‚“: 28æ­³ã€ç‹¬èº«ã€ç”·æ€§ã€‚ITä¼æ¥­å‹¤å‹™ã€å¹´å500ä¸‡ã€‚è¶£å‘³ã¯ã‚­ãƒ£ãƒ³ãƒ—ã¨ã‚µã‚¦ãƒŠã€‚åŠ¹ç‡é‡è¦–ã ãŒã€ã‚¢ãƒŠãƒ­ã‚°ãªä½“é¨“ã‚‚å¥½ãã€‚
éˆ´æœ¨ã•ã‚“: 55æ­³ã€æ—¢å©šã€å­ä¾›ç‹¬ç«‹æ¸ˆã¿ã€‚å°‚æ¥­ä¸»å©¦ã€‚å¤«ã¨äºŒäººæš®ã‚‰ã—ã€‚å¥åº·ã¨è€å¾Œã®è³‡é‡‘ãŒæ‚©ã¿ã€‚æ™‚é–“ã¯ãŸã£ã·ã‚Šã‚ã‚‹ã€‚
"""
    participants_input = st.text_area("å‚åŠ è€…ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«", value=default_participants.strip(), height=200)

    # ãƒªã‚»ãƒƒãƒˆãƒœã‚¿ãƒ³
    if st.button("è¨­å®šã‚’ä¿å­˜ã—ã¦ãƒªã‚»ãƒƒãƒˆ"):
        st.session_state.messages = []
        st.session_state.turn_count = 0
        st.session_state.participants_data = {}
        
        # å‚åŠ è€…æƒ…å ±ã®ãƒ‘ãƒ¼ã‚¹
        lines = participants_input.strip().split('\n')
        for line in lines:
            if ":" in line:
                name, profile = line.split(":", 1)
                st.session_state.participants_data[name.strip()] = profile.strip()
        st.success("ãƒªã‚»ãƒƒãƒˆã—ã¾ã—ãŸ")

# --- ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ– ---
if "messages" not in st.session_state:
    st.session_state.messages = []
if "turn_count" not in st.session_state:
    st.session_state.turn_count = 0 # ã‚¿ãƒ¼ãƒ³æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
if "participants_data" not in st.session_state:
    st.session_state.participants_data = {}
    lines = participants_input.strip().split('\n')
    for line in lines:
        if ":" in line:
            name, profile = line.split(":", 1)
            st.session_state.participants_data[name.strip()] = profile.strip()

# --- è¨ˆç®—ãƒ­ã‚¸ãƒƒã‚¯: 1ã‚¿ãƒ¼ãƒ³ï¼ç´„5åˆ†ã¨ä»®å®š ---
MINUTES_PER_TURN = 5 

def get_current_progress():
    """ç¾åœ¨ã®çµŒéæ™‚é–“ã¨é€²æ—ç‡ã‚’è¨ˆç®—"""
    current_min = st.session_state.turn_count * MINUTES_PER_TURN
    progress_pct = min(current_min / target_duration * 100, 100)
    return current_min, progress_pct

# --- é–¢æ•°å®šç¾© ---

def get_chat_response(system_prompt, user_prompt, model="gpt-3.5-turbo"):
    try:
        response = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.7
        )
        return response.choices[0].message.content
    except Exception as e:
        st.error(f"Error: {e}")
        return None

def generate_moderator_speak(history, topic, p_data):
    """ãƒ¢ãƒ‡ãƒ¬ãƒ¼ã‚¿ãƒ¼ã®ç™ºè¨€ç”Ÿæˆï¼ˆæ™‚é–“ç®¡ç†æ„è­˜ä»˜ãï¼‰"""
    p_list_str = "\n".join([f"- {name}: {prof}" for name, prof in p_data.items()])
    
    current_min, progress_pct = get_current_progress()
    
    # é€²æ—ã«å¿œã˜ãŸæŒ‡ç¤º
    time_instruction = ""
    if progress_pct < 20:
        time_instruction = "ç¾åœ¨ã¯ã€åºç›¤ï¼ˆã‚¢ã‚¤ã‚¹ãƒ–ãƒ¬ã‚¤ã‚¯ï¼‰ã€‘ã§ã™ã€‚ã¾ã æ ¸å¿ƒã«ã¯è§¦ã‚Œãšã€å‚åŠ è€…ã®ç·Šå¼µã‚’ã»ãã—ã€ãƒ©ãƒãƒ¼ãƒ«ï¼ˆä¿¡é ¼é–¢ä¿‚ï¼‰ã‚’ç¯‰ããŸã‚ã®é›‘è«‡ã‚„ãƒ©ã‚¤ãƒˆãªè³ªå•ã‚’ã—ã¦ãã ã•ã„ã€‚"
    elif progress_pct < 80:
        time_instruction = "ç¾åœ¨ã¯ã€ä¸­ç›¤ï¼ˆæ·±æ˜ã‚Šï¼‰ã€‘ã§ã™ã€‚å‚åŠ è€…ã®å›ç­”ã‹ã‚‰ã€Œãªãœãã†æ€ã†ã®ã‹ï¼Ÿã€ã¨ã„ã†èƒŒæ™¯ã‚„ä¾¡å€¤è¦³ã€ã‚¤ãƒ³ã‚µã‚¤ãƒˆã‚’æ·±ãæ˜ã‚Šä¸‹ã’ã¦ãã ã•ã„ã€‚"
    else:
        time_instruction = "ç¾åœ¨ã¯ã€çµ‚ç›¤ï¼ˆã¾ã¨ã‚ï¼‰ã€‘ã§ã™ã€‚ã“ã‚Œã¾ã§ã®è­°è«–ã‚’æ•´ç†ã—ã€è¨€ã„æ®‹ã—ãŸã“ã¨ãŒãªã„ã‹ç¢ºèªã—ã€ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼ã‚’ç· ã‚ããã‚‹æ–¹å‘ã¸é€²ã‚ã¦ãã ã•ã„ã€‚"

    system_prompt = f"""
    ã‚ãªãŸã¯ç†Ÿç·´ã—ãŸFGIãƒ¢ãƒ‡ãƒ¬ãƒ¼ã‚¿ãƒ¼ã§ã™ã€‚
    
    ## ãƒ†ãƒ¼ãƒ
    {topic}
    
    ## æ™‚é–“ç®¡ç†æƒ…å ±
    - å…¨ä½“äºˆå®šæ™‚é–“: {target_duration}åˆ†
    - ç¾åœ¨ã®çµŒéæ™‚é–“ï¼ˆç›®å®‰ï¼‰: {current_min}åˆ†
    - {time_instruction}
    
    ## é€²è¡Œãƒ«ãƒ¼ãƒ«
    1. å‚åŠ è€…ã¨ã®è·é›¢æ„Ÿã‚’å¤§åˆ‡ã«ã™ã‚‹ã€‚
    2. å…¨å“¡ã«è©±ã‚’æŒ¯ã‚‹ã€ã¾ãŸã¯ç‰¹å®šã®èˆˆå‘³æ·±ã„ç™ºè¨€ã‚’æ·±æ˜ã‚Šã™ã‚‹ã€‚
    3. ä¸€åº¦ã®ç™ºè¨€ã¯é•·ã™ããªã„ã‚ˆã†ã«ã€‚
    
    ## å‚åŠ è€…æƒ…å ±
    {p_list_str}
    """
    
    user_prompt = f"""
    ã“ã‚Œã¾ã§ã®ä¼šè©±å±¥æ­´ï¼š
    {history}
    
    ç¾åœ¨ã®çŠ¶æ³ï¼ˆ{current_min}åˆ†çµŒé / {target_duration}åˆ†äºˆå®šï¼‰ã‚’è¸ã¾ãˆã¦ã€ãƒ¢ãƒ‡ãƒ¬ãƒ¼ã‚¿ãƒ¼ã¨ã—ã¦æ¬¡ã®ç™ºè¨€ã‚’ã—ã¦ãã ã•ã„ã€‚
    """
    
    return get_chat_response(system_prompt, user_prompt, model="gpt-4o")

def generate_participant_speak(name, profile, history, topic):
    """å‚åŠ è€…ã®ç™ºè¨€ç”Ÿæˆ"""
    system_prompt = f"""
    ã‚ãªãŸã¯ä»¥ä¸‹ã®ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æŒã¤äººç‰©ã§ã™ã€‚FGIã«å‚åŠ ã—ã¦ã„ã¾ã™ã€‚
    åå‰: {name}
    è©³ç´°: {profile}
    ãƒ†ãƒ¼ãƒ: {topic}
    
    ãƒ«ãƒ¼ãƒ«:
    - ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆå¹´é½¢ã€å®¶æ—ã€æ‚©ã¿ï¼‰ã«åŸºã¥ãã€ãƒªã‚¢ãƒ«ãªå£èª¿ã§è©±ã™ã€‚
    - å»ºå‰ã ã‘ã§ãªãã€å¾ã€…ã«æœ¬éŸ³ã‚’å‡ºã™ã€‚
    - çŸ­ã™ãã‚‹å›ç­”ã¯é¿ã‘ã€ç†ç”±ã‚„ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã‚’äº¤ãˆã‚‹ã€‚
    """
    user_prompt = f"ç›´å‰ã®ä¼šè©±å±¥æ­´ã‚’è¸ã¾ãˆã€ã‚ãªãŸï¼ˆ{name}ï¼‰ã¨ã—ã¦ç™ºè¨€ã—ã¦ãã ã•ã„ã€‚\nå±¥æ­´:\n{history}"
    return get_chat_response(system_prompt, user_prompt)

# --- ãƒ¡ã‚¤ãƒ³ã‚¨ãƒªã‚¢ ---

# é€²æ—ãƒãƒ¼ã®è¡¨ç¤º
curr_min, prog_pct = get_current_progress()
st.progress(int(prog_pct))
st.caption(f"â±ï¸ çµŒéæ™‚é–“: ç´„ {curr_min} åˆ† / {target_duration} åˆ† ï¼ˆã‚¿ãƒ¼ãƒ³æ•°: {st.session_state.turn_count}ï¼‰")

# 1. å±¥æ­´è¡¨ç¤º
chat_container = st.container()
with chat_container:
    for msg in st.session_state.messages:
        role = msg["role"]
        avatar = "ğŸ§‘â€ğŸ’¼" if role == "Moderator" else "ğŸ‘¤"
        with st.chat_message(role, avatar=avatar):
            st.markdown(f"**{role}**: {msg['content']}")

# å±¥æ­´ãƒ†ã‚­ã‚¹ãƒˆä½œæˆ
history_text = ""
for msg in st.session_state.messages[-15:]:
    history_text += f"{msg['role']}: {msg['content']}\n"

# 2. ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒœã‚¿ãƒ³
st.divider()

col1, col2, col3 = st.columns(3)

def run_one_cycle():
    """ãƒ¢ãƒ‡ãƒ¬ãƒ¼ã‚¿ãƒ¼ç™ºè¨€ -> å…¨å“¡å›ç­” ã®1ã‚»ãƒƒãƒˆã‚’å®Ÿè¡Œ"""
    # ãƒ¢ãƒ‡ãƒ¬ãƒ¼ã‚¿ãƒ¼
    mod_text = generate_moderator_speak(history_text, topic, st.session_state.participants_data)
    if mod_text:
        st.session_state.messages.append({"role": "Moderator", "content": mod_text})
        
        # å‚åŠ è€…ï¼ˆãƒ¢ãƒ‡ãƒ¬ãƒ¼ã‚¿ãƒ¼ã®ç™ºè¨€ã‚’å«ã‚ãŸå±¥æ­´ã‚’æ¸¡ã™ï¼‰
        current_history = history_text + f"Moderator: {mod_text}\n"
        for p_name, p_profile in st.session_state.participants_data.items():
            p_text = generate_participant_speak(p_name, p_profile, current_history, topic)
            if p_text:
                st.session_state.messages.append({"role": p_name, "content": p_text})
                current_history += f"{p_name}: {p_text}\n"
        
        # ã‚¿ãƒ¼ãƒ³æ•°ã‚’åŠ ç®—
        st.session_state.turn_count += 1

with col1:
    if st.button("ğŸ™ï¸ 1ã‚¿ãƒ¼ãƒ³é€²ã‚ã‚‹ (æ‰‹å‹•)", use_container_width=True):
        with st.spinner("ä¼šè©±ã‚’ç”Ÿæˆä¸­..."):
            run_one_cycle()
            st.rerun()

with col2:
    # 15åˆ†ç›¸å½“ = 3ã‚¿ãƒ¼ãƒ³ã¨å®šç¾©
    if st.button("â© 15åˆ†ä¸€æ°—ã«é€²ã‚ã‚‹ (è‡ªå‹•)", type="primary", use_container_width=True):
        with st.spinner("15åˆ†åˆ†ã®è­°è«–ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ä¸­...ï¼ˆå°‘ã—æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™ï¼‰"):
            for _ in range(3): # 3å›ãƒ«ãƒ¼ãƒ—
                # å±¥æ­´æ›´æ–°ã®ãŸã‚å†å–å¾—
                temp_hist = ""
                for msg in st.session_state.messages[-15:]:
                    temp_hist += f"{msg['role']}: {msg['content']}\n"
                
                # ã‚µã‚¤ã‚¯ãƒ«å®Ÿè¡Œ
                # ã“ã“ã§é–¢æ•°å†…ã®history_textã¯å¤ã„ã¾ã¾ãªã®ã§ã€ä¿®æ­£ãŒå¿…è¦ã ãŒ
                # ç°¡æ˜“å®Ÿè£…ã¨ã—ã¦session_stateçµŒç”±ã§å›ã™
                
                # ãƒ¢ãƒ‡ãƒ¬ãƒ¼ã‚¿ãƒ¼
                mod_text = generate_moderator_speak(temp_hist, topic, st.session_state.participants_data)
                if mod_text:
                    st.session_state.messages.append({"role": "Moderator", "content": mod_text})
                    temp_hist += f"Moderator: {mod_text}\n"
                    
                    # å‚åŠ è€…
                    for p_name, p_profile in st.session_state.participants_data.items():
                        p_text = generate_participant_speak(p_name, p_profile, temp_hist, topic)
                        if p_text:
                            st.session_state.messages.append({"role": p_name, "content": p_text})
                            temp_hist += f"{p_name}: {p_text}\n"
                    
                    st.session_state.turn_count += 1
                    time.sleep(1) # APIåˆ¶é™å›é¿ã®ãŸã‚ã®wait
            st.rerun()

with col3:
    if st.button("ğŸ” ç¾æ™‚ç‚¹ã®ã‚¤ãƒ³ã‚µã‚¤ãƒˆåˆ†æ", use_container_width=True):
        with st.spinner("åˆ†æä¸­..."):
            all_log = "\n".join([f"{m['role']}: {m['content']}" for m in st.session_state.messages])
            insight_prompt = f"""
            ãƒ†ãƒ¼ãƒã€Œ{topic}ã€ã«ã¤ã„ã¦ã®FGIè­°äº‹éŒ²ã®åˆ†æã‚’ãŠé¡˜ã„ã—ã¾ã™ã€‚
            
            ## çŠ¶æ³
            ç¾åœ¨ã¯é–‹å§‹ã‹ã‚‰{curr_min}åˆ†çµŒéã—ãŸæ™‚ç‚¹ã§ã™ã€‚
            
            ## åˆ†æé …ç›®
            1. è­°è«–ã®ä¸»ãªãƒˆãƒ”ãƒƒã‚¯
            2. è¦‹ãˆã¦ããŸã‚¤ãƒ³ã‚µã‚¤ãƒˆï¼ˆæœªç¢ºå®šã§ã‚‚å¯ï¼‰
            3. ãƒ¢ãƒ‡ãƒ¬ãƒ¼ã‚¿ãƒ¼ã¸ã®ã‚¢ãƒ‰ãƒã‚¤ã‚¹ï¼ˆæ¬¡ã©ã“ã‚’æ·±æ˜ã‚Šã™ã¹ãã‹ï¼‰
            
            ## è­°äº‹éŒ²
            {all_log}
            """
            insight = get_chat_response(insight_prompt, "åˆ†æã—ã¦ãã ã•ã„", model="gpt-4o")
            st.session_state.messages.append({"role": "System", "content": f"ã€AIåˆ†æã€‘\n{insight}"})
            st.rerun()

# 3. ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
st.divider()
if st.session_state.messages:
    df = pd.DataFrame(st.session_state.messages)
    now = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')
    csv = df.to_csv(index=False).encode('utf-8_sig')
    st.download_button("ğŸ“ è­°äº‹éŒ²ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", data=csv, file_name=f'fgi_log_{now}.csv', mime='text/csv')
